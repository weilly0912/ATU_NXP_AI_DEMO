Warning: Unsupported TensorFlow Lite semantics for DEQUANTIZE 'Identity'. Placing on CPU instead
 - Input(s), Output and Weight tensors must have quantization parameters
   Op has tensors with missing quantization parameters: Identity

Network summary for facial_gender_detection_quant
Accelerator configuration               Ethos_U65_256
System configuration                 internal-default
Memory mode                          internal-default
Accelerator clock                                1000 MHz
Design peak SRAM bandwidth                      16.00 GB/s
Design peak DRAM bandwidth                       3.75 GB/s

Total SRAM used                                329.03 KiB
Total DRAM used                                183.17 KiB

CPU operators = 1 (2.5%)
NPU operators = 39 (97.5%)

Average SRAM bandwidth                           2.42 GB/s
Input   SRAM bandwidth                           0.86 MB/batch
Weight  SRAM bandwidth                           0.38 MB/batch
Output  SRAM bandwidth                           0.00 MB/batch
Total   SRAM bandwidth                           1.24 MB/batch
Total   SRAM bandwidth            per input      1.24 MB/inference (batch size 1)

Average DRAM bandwidth                           1.06 GB/s
Input   DRAM bandwidth                           0.00 MB/batch
Weight  DRAM bandwidth                           0.18 MB/batch
Output  DRAM bandwidth                           0.36 MB/batch
Total   DRAM bandwidth                           0.54 MB/batch
Total   DRAM bandwidth            per input      0.54 MB/inference (batch size 1)

Neural network macs                          18210408 MACs/batch
Network Tops/s                                   0.07 Tops/s

NPU cycles                                     348944 cycles/batch
SRAM Access cycles                              76656 cycles/batch
DRAM Access cycles                             208597 cycles/batch
On-chip Flash Access cycles                         0 cycles/batch
Off-chip Flash Access cycles                        0 cycles/batch
Total cycles                                   512962 cycles/batch

Batch Inference time                 0.51 ms, 1949.46 inferences/s (batch size 1)

